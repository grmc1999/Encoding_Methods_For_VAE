{
    "experiment_state": "waiting",
    "optimizer": {
        "lr": 0.0001,
        "capturable": false
    },
    "trainer": {
        "model": null,
        "epochs": 200,
        "folds": 2,
        "batch_size": 2048,
        "use_cuda": true,
        "data_dir": null,
        "in_device": "cuda:0",
        "num_workers": 10,
        "args": [
            "x"
        ]
    },
    "transforms": {
        "Tuple_to_dict": {},
        "MultiInputToTensor": {
            "metadata": []
        }
    },
    "model": {
        "model_class": "pytorch_VAE",
        "model_name": "Unpaired_Flexible_Encoding_Decoding_VAE",
        "sub_modules": {
            "encoding_decoding_module": {
                "module_type": "Asymmetrical_CNN_DNN_EDM",
                "parameters": {
                    "encoder_parameters": {
                        "repr_sizes": [
                            1,
                            8,
                            32,
                            32,
                            32
                        ],
                        "kernel_size": 5,
                        "activators": {
                            "name": "LeakyReLU",
                            "params": {}
                        },
                        "pooling": false,
                        "batch_norm": false,
                        "dropout": null,
                        "stride": [
                            2,
                            2,
                            1,
                            1
                        ]
                    },
                    "decoder_parameters": {
                        "image_shape": [
                            28,
                            28,
                            1
                        ],
                        "patch_shape": [
                            7,
                            7
                        ],
                        "Transformer_layers_sizes": [
                            589,
                            1078,
                            1568
                        ],
                        "Attention_mechanisms": "Dot_product_attention",
                        "layers_heads": [
                            4
                        ],
                        "layer_head_sizes": [
                            100,
                            589,
                            1078
                        ],
                        "dropout": 0.5,
                        "batch_norm": false,
                        "pre_batch_norm": false,
                        "pre_activator": {
                            "name": "LeakyReLU",
                            "params": {}
                        },
                        "pre_dropout": 0.5
                    },
                    "flat": true,
                    "deflat": false,
                    "compression_factor": 2.0,
                    "i_shape": [
                        28,
                        28
                    ],
                    "Enc_type": "CNN_ENC",
                    "Dec_type": "ViT_DEC"
                }
            },
            "P_NET": {
                "variational_generation_type": "VAE_NETs",
                "parameters": {
                    "layer_size": [
                        1568,
                        1568
                    ],
                    "dec_activators": {
                        "name": "LeakyReLU",
                        "params": {}
                    },
                    "batch_norm": false,
                    "dropout": null
                }
            },
            "Q_NET": {
                "variational_generation_type": "VAE_NETs",
                "parameters": {
                    "layer_size": [
                        1568,
                        1568
                    ],
                    "enc_activators": {
                        "name": "Sigmoid",
                        "params": {}
                    },
                    "batch_norm": false,
                    "dropout": null
                }
            }
        },
        "model_params": {
            "losses_weigths": {
                "reconstructive": 0.5,
                "generative": 0.5
            },
            "resize": [
                28,
                28
            ]
        }
    },
    "error": "Given groups=1, weight of size [32, 3, 5, 5], expected input[2048, 1, 28, 28] to have 3 channels, but got 1 channels instead"
}